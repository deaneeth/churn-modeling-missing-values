# 📊 Customer Churn Prediction – EDA & Data Preprocessing Pipeline

A beginner-to-intermediate-friendly project that walks you through the **entire journey of preparing data** for customer churn prediction — one notebook at a time. 🧪

🚀 **This repo is updated weekly** with:
- Clean, progressive Jupyter notebooks
- Raw & processed datasets
- Practical examples using Python & pandas
- Real-world-style applied EDA for churn modeling

---

## 🧭 What's Inside?

This project covers the **complete preprocessing & EDA pipeline**, built step-by-step:

| Notebook                         | Description                                    |
|----------------------------------|------------------------------------------------|
| `0_handle_missing_values.ipynb` | Identify & handle missing values using LLM     |
| `1_handle_outliers.ipynb`       | Detect & treat outliers (in progress)          |
| *Coming soon...*                | Feature scaling, encoding, correlation, etc.   |

📁 **Folder structure:**
- 📂 raw/ → raw input dataset
- 📂 processed/ → cleaned and transformed versions
- 📓 Notebooks → each preprocessing step in a separate notebook

---

## 🛠️ Tools Used

- Python, Pandas, Pydantic
- groq LLM (for smart imputations)
- Matplotlib, Seaborn
- Scikit-learn *(soon)*

---

## 🎯 Goals

- Learn to **preprocess churn data like a pro**
- Understand applied EDA, not just charts
- Build a fully cleaned, ML-ready dataset
- Serve as a template for your own ML projects

---

## 🌟 Why You’ll Like It

- 📚 Step-by-step & easy to follow
- 🧠 LLM-assisted imputations (cool and practical!)
- 🧼 Realistic focus on *data cleaning*, not just modeling
- 💾 Includes raw + processed data files

---

## 🤝 Contribute or Follow Along

This repo is evolving *week by week*. Star ⭐ to stay updated. Fork 🍴 to experiment. Contributions & feedback welcome!

---

### 👀 Want to learn how data scientists **actually clean data** before modeling?  
You’re in the right place. Let's build this together.